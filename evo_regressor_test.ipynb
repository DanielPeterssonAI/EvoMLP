{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin_europe</th>\n",
       "      <th>origin_japan</th>\n",
       "      <th>origin_usa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year  origin_europe  origin_japan  origin_usa  \n",
       "0          70              0             0           1  \n",
       "1          70              0             0           1  \n",
       "2          70              0             0           1  \n",
       "3          70              0             0           1  \n",
       "4          70              0             0           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"mpg\")\n",
    "\n",
    "X_train, y_train = df[~df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]], df[~df[\"horsepower\"].isna()][\"horsepower\"]\n",
    "X_pred = df[df[\"horsepower\"].isna()][[\"displacement\", \"acceleration\"]]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_pred)\n",
    "y_pred = np.round(y_pred)\n",
    "df.loc[X_pred.index, \"horsepower\"] = y_pred\n",
    "df = pd.get_dummies(df.drop(\"name\", axis = 1), columns = [\"origin\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop([\"mpg\"], axis = 1).values, df[\"mpg\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evolutionary_algos import EvoMLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 11.47729651839145 - val_loss: 10.797554693616892\n",
      "Epoch 1 - loss: 9.650244530343594 - val_loss: 9.363033717148546\n",
      "Epoch 2 - loss: 9.207527364413783 - val_loss: 9.197177534405714\n",
      "Epoch 3 - loss: 8.084616554140132 - val_loss: 9.734644144265024\n",
      "Epoch 4 - loss: 6.305441418301813 - val_loss: 7.456975627026308\n",
      "Epoch 7 - loss: 5.932342757460538 - val_loss: 5.585084707810168\n",
      "Epoch 8 - loss: 5.85655696656713 - val_loss: 6.780661323690616\n",
      "Epoch 12 - loss: 5.611324589434035 - val_loss: 5.130731185559079\n",
      "Epoch 14 - loss: 5.562353665810678 - val_loss: 5.986210784743693\n",
      "Epoch 19 - loss: 5.531463831026204 - val_loss: 5.350248957892359\n",
      "Epoch 20 - loss: 4.481168999406992 - val_loss: 4.099212342625239\n",
      "Epoch 28 - loss: 4.367844381101649 - val_loss: 4.711231555082381\n",
      "Epoch 34 - loss: 4.22281663849945 - val_loss: 4.046843643120317\n",
      "Epoch 40 - loss: 3.8188455118952254 - val_loss: 3.855389954521052\n",
      "Epoch 41 - loss: 3.7134910566832846 - val_loss: 3.21303272263294\n",
      "Epoch 49 - loss: 3.447950792676604 - val_loss: 2.9522845791964567\n",
      "Epoch 54 - loss: 3.314085756849849 - val_loss: 2.9787603128150257\n",
      "Epoch 55 - loss: 2.935216177301868 - val_loss: 2.9209825025301424\n",
      "Epoch 56 - loss: 2.7487198372687325 - val_loss: 3.0041097466158324\n",
      "Epoch 63 - loss: 2.6970101986953323 - val_loss: 2.5717208011682686\n",
      "Epoch 82 - loss: 2.627313861704512 - val_loss: 2.416094657561955\n",
      "Epoch 83 - loss: 2.622350124823152 - val_loss: 2.312449202972414\n",
      "Epoch 85 - loss: 2.5684340719527468 - val_loss: 2.83457744566691\n",
      "Epoch 86 - loss: 2.3660183769709264 - val_loss: 2.3015872923665874\n",
      "Epoch 124 - loss: 2.340196900523317 - val_loss: 2.344652823844588\n",
      "Epoch 132 - loss: 2.3111279140484275 - val_loss: 2.3101980061857352\n",
      "Epoch 133 - loss: 2.3077443515985556 - val_loss: 2.509340846065393\n",
      "Epoch 139 - loss: 2.255158643691195 - val_loss: 2.483003806396721\n",
      "Epoch 148 - loss: 2.2549270492526254 - val_loss: 2.35686632794268\n",
      "Epoch 153 - loss: 2.2431469518178146 - val_loss: 2.386828065363834\n",
      "Epoch 156 - loss: 2.228531974858211 - val_loss: 2.1179884796252493\n",
      "Epoch 157 - loss: 2.2257237034888817 - val_loss: 2.181062868690101\n",
      "Epoch 161 - loss: 2.2150985904004807 - val_loss: 2.227233183518607\n",
      "Epoch 162 - loss: 2.2094828277300476 - val_loss: 2.3130716893416388\n",
      "Epoch 164 - loss: 2.2054267592276986 - val_loss: 2.124545368635797\n",
      "Epoch 170 - loss: 2.191789565985467 - val_loss: 2.189675237779764\n",
      "Epoch 172 - loss: 2.1853657758589744 - val_loss: 2.261970274120481\n",
      "Epoch 173 - loss: 2.182243685483636 - val_loss: 2.3054556842513203\n",
      "Epoch 177 - loss: 2.167307218205805 - val_loss: 2.282806227887169\n",
      "Epoch 183 - loss: 2.161260981519489 - val_loss: 2.1474890916485956\n",
      "Epoch 186 - loss: 2.1466054092335978 - val_loss: 2.268413026217249\n",
      "Epoch 198 - loss: 2.1305551884362477 - val_loss: 2.1530274245105288\n",
      "Epoch 218 - loss: 2.126679934468281 - val_loss: 2.28751306469639\n",
      "Epoch 221 - loss: 2.1141853367413175 - val_loss: 2.1214797837280686\n",
      "Epoch 269 - loss: 2.1105578571704857 - val_loss: 2.133399498085246\n",
      "Epoch 272 - loss: 2.10822863232598 - val_loss: 2.1542834240767776\n",
      "Epoch 276 - loss: 2.1046189994088658 - val_loss: 2.1593133188697733\n",
      "Epoch 280 - loss: 2.104116364058734 - val_loss: 2.137714852885826\n",
      "Epoch 284 - loss: 2.103426618170212 - val_loss: 2.1197980520973125\n",
      "Epoch 292 - loss: 2.095093782865977 - val_loss: 2.1458841407673477\n",
      "Epoch 320 - loss: 2.0942427215783113 - val_loss: 2.1638763715543634\n",
      "Epoch 332 - loss: 2.094167442750416 - val_loss: 2.145109384297508\n",
      "Epoch 338 - loss: 2.088432370664648 - val_loss: 2.137716963782637\n",
      "Epoch 339 - loss: 2.0875962976017868 - val_loss: 2.0889878379795492\n",
      "Epoch 345 - loss: 2.0796649957770996 - val_loss: 2.1545761752986388\n",
      "Epoch 368 - loss: 2.0780228238883915 - val_loss: 2.1042868806544703\n",
      "Epoch 377 - loss: 2.07170479652908 - val_loss: 2.128996078911552\n",
      "Epoch 387 - loss: 2.0711752520729547 - val_loss: 2.0713859953742935\n",
      "Epoch 389 - loss: 2.065728385436387 - val_loss: 2.0170137864689854\n",
      "Epoch 391 - loss: 2.059235937419037 - val_loss: 2.0868831470910223\n",
      "Epoch 416 - loss: 2.058349048261029 - val_loss: 2.035311733571967\n",
      "Epoch 422 - loss: 2.0554732537146 - val_loss: 2.0798731497844924\n",
      "Epoch 438 - loss: 2.0534098961909666 - val_loss: 2.0625993595166294\n",
      "Epoch 448 - loss: 2.0513427940519326 - val_loss: 2.1054734017307632\n",
      "Epoch 473 - loss: 2.050804818147956 - val_loss: 2.0700151000376423\n",
      "Epoch 502 - loss: 2.0444193192517255 - val_loss: 2.021226303832186\n",
      "Epoch 569 - loss: 2.043963612090327 - val_loss: 2.0987763564613013\n",
      "Epoch 580 - loss: 2.0425577223929507 - val_loss: 2.039423482155167\n",
      "Epoch 630 - loss: 2.0376992110848744 - val_loss: 2.051361079533769\n",
      "Epoch 648 - loss: 2.0371348274280763 - val_loss: 2.021388791466726\n",
      "Epoch 728 - loss: 2.0359330195632466 - val_loss: 2.0622673988855516\n",
      "Epoch 743 - loss: 2.0354779333189157 - val_loss: 2.0426618044578957\n",
      "Epoch 744 - loss: 2.03214556875867 - val_loss: 2.016820393294656\n",
      "Epoch 827 - loss: 2.03169982314793 - val_loss: 1.990108525068082\n",
      "Epoch 833 - loss: 2.026611910325764 - val_loss: 2.05719366118657\n",
      "Epoch 841 - loss: 2.0237640267789416 - val_loss: 1.9927547843145839\n",
      "Epoch 873 - loss: 2.0220560502011784 - val_loss: 1.995509550651929\n",
      "Epoch 878 - loss: 2.0217683639622326 - val_loss: 2.0478935011460218\n",
      "Epoch 882 - loss: 2.0213114243064263 - val_loss: 2.0334986713338865\n",
      "Epoch 892 - loss: 2.020315464161399 - val_loss: 2.0129241208907565\n",
      "Epoch 924 - loss: 2.020140614745418 - val_loss: 2.0323101180218286\n",
      "Epoch 929 - loss: 2.017238719042212 - val_loss: 1.9951548031979196\n",
      "Epoch 942 - loss: 2.015725473411091 - val_loss: 2.068413045254713\n",
      "Epoch 1008 - loss: 2.0147995612343506 - val_loss: 2.053575422523734\n",
      "Epoch 1021 - loss: 2.012938029940344 - val_loss: 2.072094916936809\n",
      "Epoch 1036 - loss: 2.0113845418088467 - val_loss: 2.010721351724123\n",
      "Epoch 1070 - loss: 2.005242572239835 - val_loss: 2.0591531341426985\n",
      "Epoch 1139 - loss: 1.9991521327981567 - val_loss: 2.0644116832052317\n",
      "Epoch 1325 - loss: 1.9967805774842657 - val_loss: 2.0559860797371785\n",
      "Epoch 1383 - loss: 1.9952428282196335 - val_loss: 2.0296259478021286\n",
      "Epoch 1391 - loss: 1.9947411671766329 - val_loss: 2.044350979084075\n",
      "Epoch 1407 - loss: 1.9946881096862952 - val_loss: 2.09588043630209\n",
      "Epoch 1470 - loss: 1.99410105823827 - val_loss: 2.042886713068731\n",
      "Epoch 1481 - loss: 1.9932526880598191 - val_loss: 2.0296578681232886\n",
      "Epoch 1495 - loss: 1.9891352502331292 - val_loss: 2.0624245361621902\n",
      "Epoch 1530 - loss: 1.9886119847413 - val_loss: 2.02971354878756\n",
      "Epoch 1545 - loss: 1.9824737938354862 - val_loss: 2.0210952670894256\n",
      "Epoch 1662 - loss: 1.9824128617853942 - val_loss: 2.008554436876346\n",
      "Epoch 1667 - loss: 1.9824064604778036 - val_loss: 2.001522612951517\n",
      "Epoch 1675 - loss: 1.9822324451360456 - val_loss: 1.9258128501730538\n",
      "Epoch 1711 - loss: 1.9778552412865573 - val_loss: 1.9578012516826078\n",
      "Epoch 1714 - loss: 1.976767406154924 - val_loss: 2.001146743240593\n",
      "Epoch 1815 - loss: 1.9762839704774329 - val_loss: 2.0351537768826367\n",
      "Epoch 1858 - loss: 1.974069444179925 - val_loss: 1.984986090833781\n",
      "Epoch 1892 - loss: 1.9730695280314332 - val_loss: 2.027680755085646\n",
      "Epoch 1902 - loss: 1.9705073442644228 - val_loss: 1.9767824274155266\n",
      "Epoch 1922 - loss: 1.9678917440873023 - val_loss: 2.009896374154515\n",
      "Epoch 1944 - loss: 1.9649092200294949 - val_loss: 1.9669752030211243\n",
      "Epoch 2095 - loss: 1.963856651734928 - val_loss: 1.9735803384592248\n",
      "Epoch 2251 - loss: 1.963590566776056 - val_loss: 2.026433179054238\n",
      "Epoch 2345 - loss: 1.9625646685984148 - val_loss: 1.9920340370233842\n",
      "Epoch 2413 - loss: 1.9599533224561114 - val_loss: 1.9611486200393309\n",
      "Epoch 2553 - loss: 1.959123103787599 - val_loss: 2.0146113519739766\n",
      "Epoch 2836 - loss: 1.9572469914635922 - val_loss: 1.9782071156875698\n",
      "Epoch 3068 - loss: 1.9541227913100245 - val_loss: 1.9961257019482255\n",
      "Epoch 3214 - loss: 1.9540118430061155 - val_loss: 1.964558304466791\n",
      "Epoch 3229 - loss: 1.9531923953298163 - val_loss: 1.9666826235773005\n",
      "Epoch 3290 - loss: 1.9526996591376384 - val_loss: 1.9828633448378743\n",
      "Epoch 3325 - loss: 1.9515957751559383 - val_loss: 1.9912659774464772\n",
      "Epoch 3359 - loss: 1.9508154876527886 - val_loss: 1.9605304429638282\n",
      "Epoch 3433 - loss: 1.9502715196681457 - val_loss: 1.9443822619515854\n",
      "Epoch 3449 - loss: 1.9482232447900292 - val_loss: 1.957058098461712\n",
      "Epoch 3668 - loss: 1.947933521853441 - val_loss: 1.986271762052271\n",
      "Epoch 3690 - loss: 1.9461276760166817 - val_loss: 1.9999704992696514\n",
      "Epoch 3793 - loss: 1.9453019440158716 - val_loss: 1.9445666062535298\n",
      "Epoch 3867 - loss: 1.9429783032288774 - val_loss: 1.9634184202092306\n",
      "Epoch 3893 - loss: 1.9417155680231224 - val_loss: 1.948372311597204\n",
      "Epoch 3945 - loss: 1.9398243991118818 - val_loss: 1.9445934266136249\n",
      "Epoch 3960 - loss: 1.9382502235560726 - val_loss: 1.970933609069657\n",
      "Epoch 3992 - loss: 1.936470182901345 - val_loss: 1.96913189731156\n",
      "Epoch 4072 - loss: 1.9358857062050814 - val_loss: 1.9213667134951287\n",
      "Epoch 4079 - loss: 1.9345669616710368 - val_loss: 1.9913309197884004\n",
      "Epoch 4116 - loss: 1.93449955936019 - val_loss: 1.9548841813768127\n",
      "Epoch 4146 - loss: 1.9341383471966491 - val_loss: 1.989458621890401\n",
      "Epoch 4191 - loss: 1.9332262781887382 - val_loss: 2.012429745958157\n",
      "Epoch 4200 - loss: 1.9331377543533994 - val_loss: 1.9967956956034918\n",
      "Epoch 4204 - loss: 1.9328677180861913 - val_loss: 2.020365339516443\n",
      "Epoch 4205 - loss: 1.931650497782548 - val_loss: 1.9873470096910826\n",
      "Epoch 4265 - loss: 1.9272060934589905 - val_loss: 1.9791904732419496\n",
      "Epoch 4400 - loss: 1.9269655996310795 - val_loss: 1.904697765120845\n",
      "Epoch 4412 - loss: 1.9261260530036763 - val_loss: 1.9381700434831086\n",
      "Epoch 4437 - loss: 1.9235758678138597 - val_loss: 1.9417239654962715\n",
      "Epoch 4487 - loss: 1.921648119517875 - val_loss: 1.9134632025177418\n",
      "Epoch 4661 - loss: 1.920213089561292 - val_loss: 1.8809946404978413\n",
      "Epoch 4675 - loss: 1.9190515024339498 - val_loss: 1.9150784099828038\n",
      "Epoch 4829 - loss: 1.918422856575432 - val_loss: 1.862519918298655\n",
      "Epoch 4895 - loss: 1.9173674753914378 - val_loss: 1.9309113550843364\n",
      "Epoch 4905 - loss: 1.9167411841992061 - val_loss: 1.8712679054065675\n",
      "Epoch 5156 - loss: 1.9167287374897184 - val_loss: 1.8963129978090358\n",
      "Epoch 5180 - loss: 1.9162549700700289 - val_loss: 1.9037980733349216\n",
      "Epoch 5263 - loss: 1.9151782361638443 - val_loss: 1.8975622395772802\n",
      "Epoch 5289 - loss: 1.9139690288068165 - val_loss: 1.9323829816230649\n",
      "Epoch 5344 - loss: 1.9132653715038108 - val_loss: 1.8775390914267198\n",
      "Epoch 5355 - loss: 1.9106684383815062 - val_loss: 1.8923225119120475\n",
      "Epoch 5425 - loss: 1.9069645898911252 - val_loss: 1.9009614483971133\n",
      "Epoch 5546 - loss: 1.906794776807285 - val_loss: 1.8485448458409715\n",
      "Epoch 5693 - loss: 1.9066445460772028 - val_loss: 1.892648900018116\n",
      "Epoch 5720 - loss: 1.9053655414363353 - val_loss: 1.8739320062032092\n",
      "Epoch 5727 - loss: 1.9043370996895694 - val_loss: 1.891188384105424\n",
      "Epoch 5827 - loss: 1.9039869329876569 - val_loss: 1.8733448542866271\n",
      "Epoch 5849 - loss: 1.9023992436146047 - val_loss: 1.8719718482245642\n",
      "Epoch 5851 - loss: 1.9013211586212884 - val_loss: 1.8645030462122776\n",
      "Epoch 5860 - loss: 1.9007009718637464 - val_loss: 1.8748078971079039\n",
      "Epoch 5907 - loss: 1.8996073993875373 - val_loss: 1.8788086244879552\n",
      "Epoch 6140 - loss: 1.8982041186442502 - val_loss: 1.8854810574664846\n",
      "Epoch 6191 - loss: 1.8968528263172049 - val_loss: 1.9091460574870411\n",
      "Epoch 6228 - loss: 1.8960509203841136 - val_loss: 1.8382934750586746\n",
      "Epoch 6307 - loss: 1.8958838794522046 - val_loss: 1.9068706972180067\n",
      "Epoch 6457 - loss: 1.8947779809310854 - val_loss: 1.882166665819271\n",
      "Epoch 6559 - loss: 1.8926168731241024 - val_loss: 1.9089956789768245\n",
      "Epoch 6716 - loss: 1.8923529887688664 - val_loss: 1.8557396715703818\n",
      "Epoch 6758 - loss: 1.8915305332998869 - val_loss: 1.90855566449062\n",
      "Epoch 6773 - loss: 1.890117198286923 - val_loss: 1.8531795050716702\n",
      "Epoch 6823 - loss: 1.8888733952337202 - val_loss: 1.873377668874888\n",
      "Epoch 6923 - loss: 1.88886598467231 - val_loss: 1.8802956674997156\n",
      "Epoch 6973 - loss: 1.888057345012866 - val_loss: 1.8935097160674144\n",
      "Epoch 7052 - loss: 1.8869046708523352 - val_loss: 1.9285002326464018\n",
      "Epoch 7067 - loss: 1.886094644206102 - val_loss: 1.9011578482989548\n",
      "Epoch 7441 - loss: 1.8858873106154217 - val_loss: 1.910001467017274\n",
      "Epoch 7482 - loss: 1.8854270412986587 - val_loss: 1.8836513381123723\n",
      "Epoch 7503 - loss: 1.8847336525907574 - val_loss: 1.860896281303707\n",
      "Epoch 7567 - loss: 1.8827915854865631 - val_loss: 1.8723804084410767\n",
      "Epoch 7775 - loss: 1.8823759993027178 - val_loss: 1.904076975894992\n",
      "Epoch 7777 - loss: 1.881264701717936 - val_loss: 1.8866516536080482\n",
      "Epoch 7937 - loss: 1.880525467742838 - val_loss: 1.8596893622465682\n",
      "Epoch 7977 - loss: 1.8804404623646611 - val_loss: 1.9015512597824604\n",
      "Epoch 7989 - loss: 1.880352113197779 - val_loss: 1.8935574699212725\n",
      "Epoch 7990 - loss: 1.8796815934312874 - val_loss: 1.8438132939888985\n",
      "Epoch 8007 - loss: 1.8781177191767897 - val_loss: 1.871292798686698\n",
      "Epoch 8025 - loss: 1.8765931360216535 - val_loss: 1.8446152828633877\n",
      "Epoch 8136 - loss: 1.8751825286805919 - val_loss: 1.8718757134635353\n",
      "Epoch 8355 - loss: 1.8750558222692522 - val_loss: 1.8728621555589633\n",
      "Epoch 8368 - loss: 1.874724986350261 - val_loss: 1.8648513360791281\n",
      "Epoch 8377 - loss: 1.8732982830272225 - val_loss: 1.8663623300875838\n",
      "Epoch 8398 - loss: 1.872101902177703 - val_loss: 1.8767511980861005\n",
      "Epoch 8444 - loss: 1.8719633343339204 - val_loss: 1.8768079940106432\n",
      "Epoch 8639 - loss: 1.871578404617454 - val_loss: 1.88141664327555\n",
      "Epoch 8680 - loss: 1.8713822068478214 - val_loss: 1.8885001667325512\n",
      "Epoch 8686 - loss: 1.8713690204569042 - val_loss: 1.8598594949616836\n",
      "Epoch 8693 - loss: 1.8681820403634941 - val_loss: 1.8828828264960022\n",
      "Epoch 8810 - loss: 1.8659399312172935 - val_loss: 1.8866027089586375\n",
      "Epoch 8858 - loss: 1.865580958495336 - val_loss: 1.860220104984954\n",
      "Epoch 9010 - loss: 1.8650145867589576 - val_loss: 1.8604705614694486\n",
      "Epoch 9031 - loss: 1.8646202867871007 - val_loss: 1.8914817185705082\n",
      "Epoch 9033 - loss: 1.8635153525164494 - val_loss: 1.8646685635903695\n",
      "Epoch 9093 - loss: 1.8629856110801883 - val_loss: 1.8717867745816636\n",
      "Epoch 9147 - loss: 1.8614114647834918 - val_loss: 1.8368364490031301\n",
      "Epoch 9320 - loss: 1.8610577080850603 - val_loss: 1.878235977371088\n",
      "Epoch 9337 - loss: 1.8608203204810476 - val_loss: 1.8630516818263494\n",
      "Epoch 9357 - loss: 1.8585189170701986 - val_loss: 1.8715828447742855\n",
      "Epoch 9367 - loss: 1.8583197293630618 - val_loss: 1.8391640243959657\n",
      "Epoch 9391 - loss: 1.857064806278643 - val_loss: 1.792633443956165\n",
      "Epoch 9494 - loss: 1.8551714465466178 - val_loss: 1.8721228602880704\n",
      "Epoch 9549 - loss: 1.8540198535380372 - val_loss: 1.8478247649675559\n",
      "Epoch 9612 - loss: 1.85287852413521 - val_loss: 1.8179258325113257\n",
      "Epoch 9654 - loss: 1.8526489591062416 - val_loss: 1.812057970802588\n",
      "Epoch 9657 - loss: 1.8514426623351437 - val_loss: 1.7912869120221342\n",
      "Epoch 9669 - loss: 1.850080447375379 - val_loss: 1.79032881213752\n",
      "Epoch 9745 - loss: 1.8451678407163044 - val_loss: 1.7959486226667465\n",
      "Epoch 9835 - loss: 1.8434586364938121 - val_loss: 1.7793658689160428\n",
      "Epoch 9863 - loss: 1.8426416406622073 - val_loss: 1.8091367283491109\n",
      "Epoch 9892 - loss: 1.8406048728984337 - val_loss: 1.808652671360456\n",
      "Epoch 9933 - loss: 1.8362566398345372 - val_loss: 1.8249495980421053\n"
     ]
    }
   ],
   "source": [
    "regressor = EvoMLPRegressor(n = 24, hidden_layers = [8], activation = \"relu\", random_state = 42, lr_target = 0.02, lr_final_decay = 0.03)\n",
    "regressor.fit(scaled_X_train, y_train, epochs = 10000, validation_data = (scaled_X_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test data: 1.5177418357046766\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = regressor.predict(scaled_X_test)\n",
    "print(f\"Loss on test data: {mean_absolute_error(y_test, y_pred)}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(regressor.training_loss_history)\n",
    "ax.plot(regressor.validation_loss_history)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a5361d98b3513d72cb4620654a80a0bb40d1ea53adf5703cbac5d5174886d6d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('EvoMLP-1oh6nhp_')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
